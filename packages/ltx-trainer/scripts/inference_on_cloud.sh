#!/bin/bash
set -e

# ==========================================
# LTX-2 äº‘ç«¯ä¸€é”®æ¨ç†è„šæœ¬
# ==========================================

# é»˜è®¤å‚æ•°
MODEL_DIR="models"
LTX_MODEL_FILENAME="ltx-2-19b-dev.safetensors"
OUTPUT_DIR="outputs/ltx2_av_lora" # è®­ç»ƒé»˜è®¤è¾“å‡ºç›®å½•

# è·å–ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
PROMPT="$1"

if [ -z "$PROMPT" ]; then
    echo "âŒ é”™è¯¯ï¼šè¯·æä¾›æç¤ºè¯ï¼"
    echo "ç”¨æ³• (æ–‡ç”Ÿè§†é¢‘): bash scripts/inference_on_cloud.sh \"æç¤ºè¯\""
    echo "ç”¨æ³• (å›¾ç”Ÿè§†é¢‘): bash scripts/inference_on_cloud.sh \"æç¤ºè¯\" \"å›¾ç‰‡è·¯å¾„\""
    exit 1
fi

echo "ğŸš€ å¼€å§‹æ¨ç†æµç¨‹..."

# 1. è‡ªåŠ¨å®šä½æ¨¡å‹è·¯å¾„
# ä¼˜å…ˆæ£€æŸ¥ /workspace (Vast.ai)
if [ -d "/workspace/LTX-2/packages/ltx-trainer/models" ]; then
    BASE_DIR="/workspace/LTX-2/packages/ltx-trainer"
else
    # å›é€€åˆ°å½“å‰ç›®å½•
    BASE_DIR="$(pwd)"
fi

LTX_MODEL_PATH="$BASE_DIR/$MODEL_DIR/$LTX_MODEL_FILENAME"
GEMMA_DIR="$BASE_DIR/$MODEL_DIR/gemma"
LORA_CHECKPOINT_DIR="$BASE_DIR/$OUTPUT_DIR/checkpoints"

# 2. æŸ¥æ‰¾æœ€æ–°çš„ LoRA æƒé‡ (æ­¥æ•°æœ€å¤§çš„ checkpoints)
echo "ğŸ” æ­£åœ¨æŸ¥æ‰¾æœ€æ–°çš„ LoRA æƒé‡..."
if [ -d "$LORA_CHECKPOINT_DIR" ]; then
    # æŸ¥æ‰¾ checkpoint-X æ–‡ä»¶å¤¹ï¼ŒæŒ‰æ•°å­—æ’åºå–æœ€å¤§
    LATEST_CHECKPOINT=$(find "$LORA_CHECKPOINT_DIR" -maxdepth 1 -name "checkpoint-*" | sort -V | tail -n 1)
    
    if [ -n "$LATEST_CHECKPOINT" ]; then
        # åœ¨ checkpoint æ–‡ä»¶å¤¹å†…æ‰¾ safetensors
        LORA_PATH=$(find "$LATEST_CHECKPOINT" -name "*.safetensors" | head -n 1)
    fi
fi

# å¦‚æœæ‰¾ä¸åˆ° checkpoint æ–‡ä»¶å¤¹ï¼Œå°è¯•ç›´æ¥åœ¨ output æ‰¾ (æŸäº›é…ç½®ä¸‹ç›´æ¥è¾“å‡º)
if [ -z "$LORA_PATH" ] || [ ! -f "$LORA_PATH" ]; then
   # å°è¯•æ‰¾ latest.safetensors
   if [ -f "$BASE_DIR/$OUTPUT_DIR/checkpoints/latest.safetensors" ]; then
       LORA_PATH="$BASE_DIR/$OUTPUT_DIR/checkpoints/latest.safetensors"
   fi
fi

if [ -z "$LORA_PATH" ]; then
    echo "âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ°è®­ç»ƒå¥½çš„ LoRA æ¨¡å‹ï¼å°†åœ¨æ—  LoRA æ¨¡å¼ä¸‹è¿è¡Œ (ä»…åŸºåº§æ¨¡å‹)ã€‚"
    echo "    (è¯·ç¡®ä¿é€šè¿‡ train_on_cloud.sh å®Œæˆäº†è®­ç»ƒ)"
else
    echo "âœ… æ‰¾åˆ° LoRA æ¨¡å‹: $LORA_PATH"
fi

# 3. æ£€æŸ¥åŸºåº§æ¨¡å‹
if [ ! -f "$LTX_MODEL_PATH" ]; then
    echo "âŒ é”™è¯¯ï¼šåŸºåº§æ¨¡å‹æœªæ‰¾åˆ°: $LTX_MODEL_PATH"
    echo "è¯·å…ˆè¿è¡Œ train_on_cloud.sh å®Œæˆæ¨¡å‹ä¸‹è½½ã€‚"
    exit 1
fi

echo "âš™ï¸  é…ç½®ä¿¡æ¯:"
echo "  - åŸºåº§æ¨¡å‹: $LTX_MODEL_PATH"
echo "  - æ–‡æœ¬ç¼–ç : $GEMMA_DIR"
echo "  - æç¤ºè¯: \"$PROMPT\""

# 4. è¿è¡Œæ¨ç†
# æ„é€ åŸºç¡€å‘½ä»¤
CMD="uv run scripts/run_inference.py \
    --base-model \"$LTX_MODEL_PATH\" \
    --text-encoder \"$GEMMA_DIR\" \
    --lora \"$LORA_PATH\" \
    --prompt \"$PROMPT\" \
    --output \"generated_result.mp4\""

# å¦‚æœæä¾›äº†å›¾ç‰‡è·¯å¾„ï¼Œåˆ™è¿½åŠ å‚æ•°
IMAGE_PATH="$2"
if [ -n "$IMAGE_PATH" ]; then
    echo "ğŸ–¼ï¸  æ£€æµ‹åˆ°è¾“å…¥å›¾ç‰‡: $IMAGE_PATH"
    CMD="$CMD --input-image \"$IMAGE_PATH\""
fi

# æ‰§è¡Œå‘½ä»¤
eval $CMD

echo "âœ… æ¨ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜ä¸º generated_result.mp4"
